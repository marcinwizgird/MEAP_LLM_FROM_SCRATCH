{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-09T06:08:44.611078Z",
     "start_time": "2026-02-09T06:08:25.438889Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:08:50.006797Z",
     "start_time": "2026-02-10T08:08:49.999714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}"
   ],
   "id": "f737b81cffb569fb",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Coding LLM Architecture",
   "id": "d9ce3bf27e63f303"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:08:07.879199Z",
     "start_time": "2026-02-10T08:08:07.871394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ],
   "id": "80e4716e56c7db3b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:08:08.130024Z",
     "start_time": "2026-02-10T08:08:08.122658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n"
   ],
   "id": "de7f3f1ee94c74ec",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:08:08.547756Z",
     "start_time": "2026-02-10T08:08:08.538960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        #Shouldn't there be the Positional Embedding implemented?\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trns_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        batch_size, seq_length = x_in.shape\n",
    "        x = x_in\n",
    "        tok_embeds  = self.tok_emb(x_in)\n",
    "        pos_emb = self.pos_emb(torch.arange(seq_length, device=x_in.device))\n",
    "        x = tok_embeds + pos_emb\n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "        x = self.trns_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ],
   "id": "d0a7ad3cd713e557",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:08:09.501481Z",
     "start_time": "2026-02-10T08:08:09.495834Z"
    }
   },
   "cell_type": "code",
   "source": "import tiktoken",
   "id": "43e8108aa38ebbab",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:08:10.818769Z",
     "start_time": "2026-02-10T08:08:10.812Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = tiktoken.get_encoding(\"gpt2\")",
   "id": "b97f039f7ba0f62",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:12:45.793222Z",
     "start_time": "2026-02-10T08:12:45.787188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\""
   ],
   "id": "f738af6f1cdb0cd8",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:12:49.188224Z",
     "start_time": "2026-02-10T08:12:49.179550Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(txt1)",
   "id": "4296b5ab1fe6e801",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6109, 3626, 6100, 345]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:13:27.079938Z",
     "start_time": "2026-02-10T08:13:27.072858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = []\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)"
   ],
   "id": "2dce1f9175f01cd2",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T08:13:27.894234Z",
     "start_time": "2026-02-10T08:13:27.884761Z"
    }
   },
   "cell_type": "code",
   "source": "batch",
   "id": "d8be8ca5a00c0430",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345],\n",
       "        [6109, 1110, 6622,  257]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:14:52.832929Z",
     "start_time": "2026-02-10T17:14:52.156377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "gptModel = DummyGPTModel(cfg=GPT_CONFIG_124M)"
   ],
   "id": "2c36facfaea701f8",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:14:55.888484Z",
     "start_time": "2026-02-10T17:14:55.864931Z"
    }
   },
   "cell_type": "code",
   "source": "logits = gptModel(batch)",
   "id": "955484c4970cc567",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:14:57.131246Z",
     "start_time": "2026-02-10T17:14:57.123803Z"
    }
   },
   "cell_type": "code",
   "source": "logits.shape",
   "id": "f7d3385f57333777",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2 Layer Normalization",
   "id": "8f926ecb00c4d883"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:14:49.445668Z",
     "start_time": "2026-02-10T18:14:49.419425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example = torch.randn(2,5)\n",
    "batch_example"
   ],
   "id": "8c22d17bf8afc39",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:14:51.644490Z",
     "start_time": "2026-02-10T18:14:51.631518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "out"
   ],
   "id": "2f960eeac2c473b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
       "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:14:59.869736Z",
     "start_time": "2026-02-10T18:14:59.860914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = out.mean(dim = -1, keepdim = True)\n",
    "var = out.var(dim = -1, keepdim = True)"
   ],
   "id": "1339f7389a6ef30c",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:15:00.540399Z",
     "start_time": "2026-02-10T18:15:00.533586Z"
    }
   },
   "cell_type": "code",
   "source": "torch.set_printoptions(sci_mode=False)",
   "id": "99453fbb0b829c5",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:15:01.058283Z",
     "start_time": "2026-02-10T18:15:01.051156Z"
    }
   },
   "cell_type": "code",
   "source": "normed = (out-mean) / torch.sqrt(var)",
   "id": "83e30b37cb61b56e",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:15:01.566839Z",
     "start_time": "2026-02-10T18:15:01.557151Z"
    }
   },
   "cell_type": "code",
   "source": "normed.mean(dim = -1)",
   "id": "16f822631510ad21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:15:02.240972Z",
     "start_time": "2026-02-10T18:15:02.229369Z"
    }
   },
   "cell_type": "code",
   "source": "normed.var(dim = -1)",
   "id": "3416d230c2e8c683",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:19:12.441580Z",
     "start_time": "2026-02-10T18:19:12.424716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True) #, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        return self.scale * norm_x + self.shift"
   ],
   "id": "60a848ad2e0ba3da",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:20:12.897980Z",
     "start_time": "2026-02-10T18:20:12.885867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ln = LayerNorm(6)\n",
    "ln_out = ln(out)\n",
    "ln_out"
   ],
   "id": "b42ea9b2dc4368ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6157,  1.4123, -0.8717,  0.5871, -0.8717, -0.8717],\n",
       "        [-0.0189,  0.1121, -1.0875,  1.5171,  0.5647, -1.0875]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:20:37.001921Z",
     "start_time": "2026-02-10T18:20:36.994365Z"
    }
   },
   "cell_type": "code",
   "source": "ln_out.mean(dim = -1)",
   "id": "828c544b76caf2c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000,  0.0000], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T18:20:57.977163Z",
     "start_time": "2026-02-10T18:20:57.965639Z"
    }
   },
   "cell_type": "code",
   "source": "ln_out.var(dim = -1)",
   "id": "77a3f15083e4e7a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9996, 0.9997], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4.3 Implementing FFN with GELU activation\n",
   "id": "8f517c5f5229d8e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T14:12:28.962095Z",
     "start_time": "2026-02-11T14:12:28.954370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor((2 / torch.pi))) * (x + 0.044715 * torch.pow(x, 3))))"
   ],
   "id": "31667a0aa308b4a6",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T14:12:30.184901Z",
     "start_time": "2026-02-11T14:12:30.155576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gelu = GELU()\n",
    "gelu(torch.tensor(-0.8))"
   ],
   "id": "ecae249dcdd50d51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1696)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T14:56:53.979343Z",
     "start_time": "2026-02-11T14:56:53.969113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\"\n",
    "            FFN sub-module of Transofrmer Block learning richer representations\n",
    "            and extract more meaningful information from the input sequence.\n",
    "            Typical Deep Learning strategy.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"]*4),\n",
    "                                         GELU(),\n",
    "                                         nn.Linear(cfg[\"emb_dim\"]*4, cfg[\"emb_dim\"])\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n"
   ],
   "id": "1e1f6fdf46b4f07d",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T14:56:54.798593Z",
     "start_time": "2026-02-11T14:56:54.737746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ffn = FeedForward(cfg=GPT_CONFIG_124M)\n",
    "ffn(torch.randn(2, 10, 768)).shape"
   ],
   "id": "fae506a3f75f248",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T14:57:01.822073Z",
     "start_time": "2026-02-11T14:57:01.811167Z"
    }
   },
   "cell_type": "code",
   "source": "ffn.layers",
   "id": "6ca69cba7baba690",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (1): GELU()\n",
       "  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T14:57:22.768402Z",
     "start_time": "2026-02-11T14:57:22.759973Z"
    }
   },
   "cell_type": "code",
   "source": "ffn.layers[0]",
   "id": "cc3af35b28f5dcc0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=3072, bias=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T16:17:09.721416Z",
     "start_time": "2026-02-11T16:17:09.710974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepNN(nn.Module):\n",
    "     def __init__(self, layer_sizes, use_shortcut=False):\n",
    "         super().__init__()\n",
    "         self.use_shortcut = use_shortcut\n",
    "         self.layers = nn.ModuleList([\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "                                       ])\n",
    "\n",
    "     def forward(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(out)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                out += layer_output\n",
    "            else:\n",
    "                out = layer_output\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ],
   "id": "e938c9a1e9eb9e06",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T16:17:10.520044Z",
     "start_time": "2026-02-11T16:17:10.498371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)                            #1\n",
    "model_without_shortcut = DeepNN(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")"
   ],
   "id": "baea16534465b503",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T16:17:29.029156Z",
     "start_time": "2026-02-11T16:17:29.017703Z"
    }
   },
   "cell_type": "code",
   "source": "model_without_shortcut(sample_input)",
   "id": "d882ff0dd3a1cd61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0610]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T16:17:20.903253Z",
     "start_time": "2026-02-11T16:17:20.895012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)             #1\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)    #2\n",
    "\n",
    "    loss.backward()          #3\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "#1 Forward pass"
   ],
   "id": "44c277ccc38b301f",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T16:17:43.913515Z",
     "start_time": "2026-02-11T16:17:43.808599Z"
    }
   },
   "cell_type": "code",
   "source": "print_gradients(model_without_shortcut, sample_input)",
   "id": "e5d849ca789fb3ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T16:20:02.635340Z",
     "start_time": "2026-02-11T16:20:02.627744Z"
    }
   },
   "cell_type": "code",
   "source": "model_with_shortcut = DeepNN(layer_sizes, use_shortcut=True)",
   "id": "b1d1df3ecc4fba52",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-11T16:20:03.291435Z",
     "start_time": "2026-02-11T16:20:03.118178Z"
    }
   },
   "cell_type": "code",
   "source": "print_gradients(model_with_shortcut, sample_input)",
   "id": "732d2330c654cf77",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 3]], which is output 0 of AddBackward0, is at version 4; expected version 3 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[120]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mprint_gradients\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_with_shortcut\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_input\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[113]\u001B[39m\u001B[32m, line 8\u001B[39m, in \u001B[36mprint_gradients\u001B[39m\u001B[34m(model, x)\u001B[39m\n\u001B[32m      5\u001B[39m loss = nn.MSELoss()\n\u001B[32m      6\u001B[39m loss = loss(output, target)    \u001B[38;5;66;03m#2\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m          \u001B[38;5;66;03m#3\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m name, param \u001B[38;5;129;01min\u001B[39;00m model.named_parameters():\n\u001B[32m     11\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mweight\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m name:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\torch\\_tensor.py:625\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    616\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    617\u001B[39m         Tensor.backward,\n\u001B[32m    618\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    623\u001B[39m         inputs=inputs,\n\u001B[32m    624\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m625\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    626\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    627\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    349\u001B[39m     retain_graph = create_graph\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m354\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs_tuple\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\DATAENLIGHT_AI_LAB\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    839\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    840\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m841\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    844\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    845\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mRuntimeError\u001B[39m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 3]], which is output 0 of AddBackward0, is at version 4; expected version 3 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef25d01a1ef5f7df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
