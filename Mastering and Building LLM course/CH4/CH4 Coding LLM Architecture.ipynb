{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.143644Z",
     "start_time": "2026-02-13T17:46:17.139022Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.255449Z",
     "start_time": "2026-02-13T17:46:17.249345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"emb_dim\": 768,          # Embedding dimension\n",
    "    \"n_heads\": 12,           # Number of attention heads\n",
    "    \"n_layers\": 12,          # Number of layers\n",
    "    \"drop_rate\": 0.1,        # Dropout rate\n",
    "    \"qkv_bias\": False        # Query-Key-Value bias\n",
    "}"
   ],
   "id": "f737b81cffb569fb",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Coding LLM Architecture",
   "id": "d9ce3bf27e63f303"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.276432Z",
     "start_time": "2026-02-13T17:46:17.266775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ],
   "id": "80e4716e56c7db3b",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.290627Z",
     "start_time": "2026-02-13T17:46:17.284453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n"
   ],
   "id": "de7f3f1ee94c74ec",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.306701Z",
     "start_time": "2026-02-13T17:46:17.300092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        #Shouldn't there be the Positional Embedding implemented?\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trns_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        batch_size, seq_length = x_in.shape\n",
    "        x = x_in\n",
    "        tok_embeds  = self.tok_emb(x_in)\n",
    "        pos_emb = self.pos_emb(torch.arange(seq_length, device=x_in.device))\n",
    "        x = tok_embeds + pos_emb\n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "        x = self.trns_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ],
   "id": "d0a7ad3cd713e557",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.321937Z",
     "start_time": "2026-02-13T17:46:17.315117Z"
    }
   },
   "cell_type": "code",
   "source": "import tiktoken",
   "id": "43e8108aa38ebbab",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.336504Z",
     "start_time": "2026-02-13T17:46:17.330880Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = tiktoken.get_encoding(\"gpt2\")",
   "id": "b97f039f7ba0f62",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.350249Z",
     "start_time": "2026-02-13T17:46:17.344818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\""
   ],
   "id": "f738af6f1cdb0cd8",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.368873Z",
     "start_time": "2026-02-13T17:46:17.361988Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(txt1)",
   "id": "4296b5ab1fe6e801",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6109, 3626, 6100, 345]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.417396Z",
     "start_time": "2026-02-13T17:46:17.412038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = []\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)"
   ],
   "id": "2dce1f9175f01cd2",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:17.444150Z",
     "start_time": "2026-02-13T17:46:17.437279Z"
    }
   },
   "cell_type": "code",
   "source": "batch",
   "id": "d8be8ca5a00c0430",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345],\n",
       "        [6109, 1110, 6622,  257]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:18.153779Z",
     "start_time": "2026-02-13T17:46:17.575708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "gptModel = DummyGPTModel(cfg=GPT_CONFIG_124M)"
   ],
   "id": "2c36facfaea701f8",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:18.227553Z",
     "start_time": "2026-02-13T17:46:18.214710Z"
    }
   },
   "cell_type": "code",
   "source": "logits = gptModel(batch)",
   "id": "955484c4970cc567",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:18.307566Z",
     "start_time": "2026-02-13T17:46:18.301542Z"
    }
   },
   "cell_type": "code",
   "source": "logits.shape",
   "id": "f7d3385f57333777",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:18.383175Z",
     "start_time": "2026-02-13T17:46:18.372444Z"
    }
   },
   "cell_type": "code",
   "source": "logits",
   "id": "7e4a8c64f0281d46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
       "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
       "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
       "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
       "\n",
       "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
       "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
       "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
       "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.2 Layer Normalization",
   "id": "8f926ecb00c4d883"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:27:11.561631Z",
     "start_time": "2026-02-13T18:27:11.541176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example = torch.randn(2,5)\n",
    "batch_example"
   ],
   "id": "8c22d17bf8afc39",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:27:12.071702Z",
     "start_time": "2026-02-13T18:27:12.061214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "out"
   ],
   "id": "2f960eeac2c473b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
       "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:27:13.394969Z",
     "start_time": "2026-02-13T18:27:13.389252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = out.mean(dim = -1, keepdim = True)\n",
    "var = out.var(dim = -1, keepdim = True)"
   ],
   "id": "1339f7389a6ef30c",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:27:13.985323Z",
     "start_time": "2026-02-13T18:27:13.978828Z"
    }
   },
   "cell_type": "code",
   "source": "torch.set_printoptions(sci_mode=False)",
   "id": "99453fbb0b829c5",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:27:14.494051Z",
     "start_time": "2026-02-13T18:27:14.487379Z"
    }
   },
   "cell_type": "code",
   "source": "normed = (out-mean) / torch.sqrt(var)",
   "id": "83e30b37cb61b56e",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:27:15.135009Z",
     "start_time": "2026-02-13T18:27:15.124947Z"
    }
   },
   "cell_type": "code",
   "source": "normed.mean(dim = -1)",
   "id": "16f822631510ad21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:27:15.819735Z",
     "start_time": "2026-02-13T18:27:15.809641Z"
    }
   },
   "cell_type": "code",
   "source": "normed.var(dim = -1)",
   "id": "3416d230c2e8c683",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:49.929248Z",
     "start_time": "2026-02-13T18:30:49.920873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        return self.scale * norm_x + self.shift"
   ],
   "id": "60a848ad2e0ba3da",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:49.955101Z",
     "start_time": "2026-02-13T18:30:49.948550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ln = LayerNorm(dim = 5)\n",
    "ln_out = ln(batch_example)\n"
   ],
   "id": "b42ea9b2dc4368ab",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:50.040678Z",
     "start_time": "2026-02-13T18:30:50.031667Z"
    }
   },
   "cell_type": "code",
   "source": "batch_example",
   "id": "2e209b7d6cb9f688",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:50.189481Z",
     "start_time": "2026-02-13T18:30:50.181138Z"
    }
   },
   "cell_type": "code",
   "source": "ln_out",
   "id": "84a012c600135efc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5528,  1.0693, -0.0223,  0.2656, -1.8654],\n",
       "        [ 0.9087, -1.3767, -0.9564,  1.1304,  0.2940]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:50.504622Z",
     "start_time": "2026-02-13T18:30:50.495274Z"
    }
   },
   "cell_type": "code",
   "source": "ln_out.mean(dim = -1)",
   "id": "828c544b76caf2c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0000,  0.0000], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:50.813932Z",
     "start_time": "2026-02-13T18:30:50.805511Z"
    }
   },
   "cell_type": "code",
   "source": "ln_out.var(dim = -1)",
   "id": "77a3f15083e4e7a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2499, 1.2500], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4.3 Implementing FFN with GELU activation\n",
   "id": "8f517c5f5229d8e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:50.965628Z",
     "start_time": "2026-02-13T18:30:50.958498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor((2 / torch.pi))) * (x + 0.044715 * torch.pow(x, 3))))"
   ],
   "id": "31667a0aa308b4a6",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.037815Z",
     "start_time": "2026-02-13T18:30:51.028211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gelu = GELU()\n",
    "gelu(torch.tensor(-0.8))"
   ],
   "id": "ecae249dcdd50d51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1696)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.161199Z",
     "start_time": "2026-02-13T18:30:51.153306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        \"\"\"\n",
    "            FFN sub-module of Transofrmer Block learning richer representations\n",
    "            and extract more meaningful information from the input sequence.\n",
    "            Typical Deep Learning strategy.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], cfg[\"emb_dim\"]*4),\n",
    "                                         GELU(),\n",
    "                                         nn.Linear(cfg[\"emb_dim\"]*4, cfg[\"emb_dim\"])\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out\n"
   ],
   "id": "1e1f6fdf46b4f07d",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.225781Z",
     "start_time": "2026-02-13T18:30:51.175029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ffn = FeedForward(cfg=GPT_CONFIG_124M)\n",
    "ffn(torch.randn(2, 10, 768)).shape"
   ],
   "id": "fae506a3f75f248",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.262279Z",
     "start_time": "2026-02-13T18:30:51.254785Z"
    }
   },
   "cell_type": "code",
   "source": "ffn.layers",
   "id": "6ca69cba7baba690",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (1): GELU()\n",
       "  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.369681Z",
     "start_time": "2026-02-13T18:30:51.361857Z"
    }
   },
   "cell_type": "code",
   "source": "ffn.layers[0]",
   "id": "cc3af35b28f5dcc0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=3072, bias=True)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.4. Adding shortcut connections",
   "id": "180886127562b763"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.441655Z",
     "start_time": "2026-02-13T18:30:51.432502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepNN(nn.Module):\n",
    "     def __init__(self, layer_sizes, use_shortcut=False):\n",
    "         super().__init__()\n",
    "         self.use_shortcut = use_shortcut\n",
    "         self.layers = nn.ModuleList([\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "                                       nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "                                       ])\n",
    "\n",
    "     def forward(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(out)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                out = out + layer_output\n",
    "            else:\n",
    "                out = layer_output\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ],
   "id": "e938c9a1e9eb9e06",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.516683Z",
     "start_time": "2026-02-13T18:30:51.498297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)                            #1\n",
    "model_without_shortcut = DeepNN(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")"
   ],
   "id": "baea16534465b503",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.560652Z",
     "start_time": "2026-02-13T18:30:51.547806Z"
    }
   },
   "cell_type": "code",
   "source": "model_without_shortcut(sample_input)",
   "id": "d882ff0dd3a1cd61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0610]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.689276Z",
     "start_time": "2026-02-13T18:30:51.683201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)             #1\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)    #2\n",
    "\n",
    "    loss.backward()          #3\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
    "#1 Forward pass"
   ],
   "id": "44c277ccc38b301f",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:51.876692Z",
     "start_time": "2026-02-13T18:30:51.866880Z"
    }
   },
   "cell_type": "code",
   "source": "print_gradients(model_without_shortcut, sample_input)",
   "id": "e5d849ca789fb3ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:52.086322Z",
     "start_time": "2026-02-13T18:30:52.074188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = DeepNN(layer_sizes, use_shortcut=True)"
   ],
   "id": "b1d1df3ecc4fba52",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:52.134798Z",
     "start_time": "2026-02-13T18:30:52.124456Z"
    }
   },
   "cell_type": "code",
   "source": "model_with_shortcut(sample_input)",
   "id": "7572f59636711bdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7669]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:52.311389Z",
     "start_time": "2026-02-13T18:30:52.300254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_input_2 = torch.tensor([[1., 0., -1.]])\n",
    "print_gradients(model_with_shortcut, sample_input_2)"
   ],
   "id": "732d2330c654cf77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169792652130127\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732502937317\n",
      "layers.4.0.weight has gradient mean of 1.3258541822433472\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.5. Connecting attention and linear layers into transformer blocks",
   "id": "599ab7154e656233"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:52.526495Z",
     "start_time": "2026-02-13T18:30:52.519103Z"
    }
   },
   "cell_type": "code",
   "source": "from ch03 import MultiHeadAttention",
   "id": "a5014d7028ff718c",
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:52.556202Z",
     "start_time": "2026-02-13T18:30:52.546451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        self.attn = MultiHeadAttention(\n",
    "                        d_in = cfg[\"emb_dim\"],\n",
    "                        d_out = cfg[\"emb_dim\"],\n",
    "                        context_length = cfg[\"context_length\"],\n",
    "                        dropout = cfg[\"drop_rate\"],\n",
    "                        num_heads = cfg[\"n_heads\"],\n",
    "                        qkv_bias = cfg[\"qkv_bias\"])\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        #MHA Block\n",
    "        out_attn = self.attn(self.norm1(x))\n",
    "        out_attn = self.dropout(out_attn)\n",
    "        out_attn = x + out_attn\n",
    "\n",
    "        #FFN Block\n",
    "        out_ffn = self.ffn(self.norm2(out_attn))\n",
    "        out_ffn = self.dropout(out_ffn)\n",
    "        out_ffn = out_attn + out_ffn\n",
    "\n",
    "        return out_ffn\n",
    "        \"\"\"\n",
    "         # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ],
   "id": "8f03b176d67ad6fd",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:52.741904Z",
     "start_time": "2026-02-13T18:30:52.662521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ],
   "id": "c9fd0f0dfb376706",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:52.988548Z",
     "start_time": "2026-02-13T18:30:52.977589Z"
    }
   },
   "cell_type": "code",
   "source": "x",
   "id": "42eca95743f7cc54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2961, 0.5166, 0.2517,  ..., 0.9541, 0.8567, 0.4604],\n",
       "         [0.2238, 0.3047, 0.3019,  ..., 0.5465, 0.4532, 0.7598],\n",
       "         [0.6945, 0.2478, 0.4111,  ..., 0.8838, 0.4898, 0.5963],\n",
       "         [0.0890, 0.7804, 0.9223,  ..., 0.4507, 0.6357, 0.5833]],\n",
       "\n",
       "        [[0.5716, 0.9297, 0.3396,  ..., 0.0477, 0.4564, 0.2797],\n",
       "         [0.0936, 0.2211, 0.3806,  ..., 0.3948, 0.4545, 0.4536],\n",
       "         [0.6788, 0.1741, 0.2084,  ..., 0.5557, 0.5930, 0.0959],\n",
       "         [0.3894, 0.4083, 0.0662,  ..., 0.9861, 0.9341, 0.1319]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:53.134230Z",
     "start_time": "2026-02-13T18:30:53.124399Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "c2d44b506e70c7ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0055,  0.0972, -0.1122,  ...,  1.2889,  0.2623,  0.6685],\n",
       "         [ 0.0023, -0.2369,  0.1720,  ...,  0.5952,  0.2497,  0.7447],\n",
       "         [ 0.4673,  0.4472,  0.1791,  ...,  1.2525,  0.3045,  0.7750],\n",
       "         [ 0.0662,  0.7224,  0.9206,  ...,  0.4790,  0.7428,  0.7015]],\n",
       "\n",
       "        [[ 0.3622,  1.2144,  0.5221,  ...,  0.1854,  0.0111, -0.5034],\n",
       "         [-0.0225,  0.7789,  0.2770,  ...,  0.1734,  0.5419,  0.1143],\n",
       "         [ 0.7425,  0.4013,  0.3211,  ...,  0.3268,  0.7523, -0.1642],\n",
       "         [ 0.5745,  0.6241,  0.4410,  ...,  1.1963,  1.2650,  0.2243]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T17:46:20.932763Z",
     "start_time": "2026-02-13T17:46:20.927135Z"
    }
   },
   "cell_type": "markdown",
   "source": "### 4.6 Coding GPT Model",
   "id": "dd0d9adc62953421"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:53.231864Z",
     "start_time": "2026-02-13T18:30:53.221473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        #Shouldn't there be the Positional Embedding implemented?\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trns_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias = False)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        batch_size, seq_length = x_in.shape\n",
    "        #x = x_in\n",
    "        tok_embeds  = self.tok_emb(x_in)\n",
    "        pos_emb = self.pos_emb(torch.arange(seq_length, device=x_in.device))\n",
    "        x = tok_embeds + pos_emb\n",
    "        x = self.drop_emb(x)\n",
    "\n",
    "        x = self.trns_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ],
   "id": "5a61e9e89bf74c9",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:54.671449Z",
     "start_time": "2026-02-13T18:30:53.262467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ],
   "id": "fa117359bb2ddc29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:54.889332Z",
     "start_time": "2026-02-13T18:30:54.880926Z"
    }
   },
   "cell_type": "code",
   "source": "model.parameters()",
   "id": "4141811a7b1eb287",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002A38571FA00>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:54.942347Z",
     "start_time": "2026-02-13T18:30:54.934524Z"
    }
   },
   "cell_type": "code",
   "source": "sum([p.numel() for p in model.parameters()])",
   "id": "c8ce989d41dbc26f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163009536"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.7 Generating Text",
   "id": "2496b61f2b734bfb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Fundamental questions:\n",
    "1. Does LLM training process consider entire sequence within one batch iteration? I think that yes.\n",
    "2. Is Loss function - cross-entropy - computed for entire non-masked sequence?"
   ],
   "id": "5022d8411ebe25bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:54.980684Z",
     "start_time": "2026-02-13T18:30:54.970418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded_text = tokenizer.encode(start_context)\n",
    "encoded_tensor = torch.tensor(encoded_text).unsqueeze(0)\n",
    "encoded_tensor.shape"
   ],
   "id": "6086a0e0a48ff3c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:55.010500Z",
     "start_time": "2026-02-13T18:30:55.001549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_text_simplified(model, idx, max_new_tokens, context_size):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = torch.softmax(logits, dim=-1) #, keepdim = True)\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim = True)\n",
    "        idx = torch.cat((idx, idx_next), dim = 1)\n",
    "\n",
    "    return idx"
   ],
   "id": "7bba4e4cb9b8832b",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:55.969474Z",
     "start_time": "2026-02-13T18:30:55.033412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out = generate_text_simplified(\n",
    "                               model,\n",
    "                               idx = encoded_tensor,\n",
    "                               max_new_tokens = 6,\n",
    "                               context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    "                               )"
   ],
   "id": "7ee29a0ef5c3c437",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:56.159389Z",
     "start_time": "2026-02-13T18:30:56.151609Z"
    }
   },
   "cell_type": "code",
   "source": "out",
   "id": "5750b407c7952a57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 38891, 34320]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-13T18:30:56.262812Z",
     "start_time": "2026-02-13T18:30:56.259766Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7c63fc3c4037ab6e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
