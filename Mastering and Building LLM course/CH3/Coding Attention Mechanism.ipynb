{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "3.3.1  simple self-attention mechanism without weights",
   "id": "2324fe7f2ea6bbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.336029Z",
     "start_time": "2025-11-13T19:30:11.331511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import manual_seed\n",
    "from win32inetcon import WINHTTP_QUERY_MAX"
   ],
   "id": "8d19f7bab9eca2e0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.377445Z",
     "start_time": "2025-11-13T19:30:11.372620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ],
   "id": "202896967699c986",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.392834Z",
     "start_time": "2025-11-13T19:30:11.387319Z"
    }
   },
   "cell_type": "code",
   "source": "input_query = inputs[1]",
   "id": "98304f08111b3a1f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.407870Z",
     "start_time": "2025-11-13T19:30:11.401734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention_scores = torch.matmul(inputs, inputs.transpose(0, 1))\n",
    "attention_weights = torch.softmax(attention_scores, dim = 1)\n",
    "context_vectors = torch.matmul(attention_weights, inputs)"
   ],
   "id": "b4fb2bd553736cb4",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.438087Z",
     "start_time": "2025-11-13T19:30:11.430775Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights",
   "id": "eaa2f94996402b9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.510940Z",
     "start_time": "2025-11-13T19:30:11.504499Z"
    }
   },
   "cell_type": "code",
   "source": "context_vectors",
   "id": "608d7c73e4427a33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:02:28.120226Z",
     "start_time": "2025-10-26T13:02:28.109156Z"
    }
   },
   "cell_type": "markdown",
   "source": "3.4 Implementing Self-Attention Weights with trainable weights",
   "id": "207ed1ef34e352f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.737658Z",
     "start_time": "2025-11-13T19:30:11.734367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ],
   "id": "bcc6bf8f7c5b2814",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.816203Z",
     "start_time": "2025-11-13T19:30:11.810023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "WQ = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "WK = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "WV = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)"
   ],
   "id": "cfef2a2a72c55de4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.834080Z",
     "start_time": "2025-11-13T19:30:11.825142Z"
    }
   },
   "cell_type": "code",
   "source": "X = inputs",
   "id": "637489a30678851f",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.846074Z",
     "start_time": "2025-11-13T19:30:11.841665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Q = X @ WQ\n",
    "K = X @ WK\n",
    "V = X @ WV"
   ],
   "id": "2cffc3830c8a63ca",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.859387Z",
     "start_time": "2025-11-13T19:30:11.854292Z"
    }
   },
   "cell_type": "code",
   "source": "Q.requires_grad",
   "id": "393760fcfd98cfbf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.890014Z",
     "start_time": "2025-11-13T19:30:11.884159Z"
    }
   },
   "cell_type": "code",
   "source": "K",
   "id": "14b2b70e5a8995be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3669, 0.7646],\n",
       "        [0.4433, 1.1419],\n",
       "        [0.4361, 1.1156],\n",
       "        [0.2408, 0.6706],\n",
       "        [0.1827, 0.3292],\n",
       "        [0.3275, 0.9642]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:11.937492Z",
     "start_time": "2025-11-13T19:30:11.933594Z"
    }
   },
   "cell_type": "code",
   "source": "attention_scores = Q @ K.transpose(0, 1)",
   "id": "1303b8a0c1032a3",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.047084Z",
     "start_time": "2025-11-13T19:30:12.040971Z"
    }
   },
   "cell_type": "code",
   "source": "attention_scores",
   "id": "d1525553f624c866",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
       "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
       "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
       "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
       "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
       "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.117976Z",
     "start_time": "2025-11-13T19:30:12.112457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#transformation normalization\n",
    "d_k = WK.shape[-1]\n",
    "attention_weights = torch.softmax(attention_scores / (d_k ** 0.5), dim = 1)"
   ],
   "id": "dcc2ac9447e6f723",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.227906Z",
     "start_time": "2025-11-13T19:30:12.222795Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights",
   "id": "f49cccd1aad43619",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
       "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
       "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
       "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
       "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
       "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.348701Z",
     "start_time": "2025-11-13T19:30:12.343504Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights.sum(dim=1)",
   "id": "d488accfacb6c8b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.456299Z",
     "start_time": "2025-11-13T19:30:12.450666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_vectors = attention_weights @ V\n",
    "context_vectors"
   ],
   "id": "d7d06a1788e5b234",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2996, 0.8053],\n",
       "        [0.3061, 0.8210],\n",
       "        [0.3058, 0.8203],\n",
       "        [0.2948, 0.7939],\n",
       "        [0.2927, 0.7891],\n",
       "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:40:09.890089Z",
     "start_time": "2025-10-28T08:40:09.880436Z"
    }
   },
   "cell_type": "markdown",
   "source": "3.4.2 Implementing compact self-attention Pytorch class",
   "id": "552cbb143bfc8bff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.567489Z",
     "start_time": "2025-11-13T19:30:12.563408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = inputs\n",
    "d_in = X.size(-1)\n",
    "d_out = 2"
   ],
   "id": "e9553ac1c866f2e9",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.657597Z",
     "start_time": "2025-11-13T19:30:12.650941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SelfAttentionV1(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out = 2, manual_seed = 123):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.manual_seed = manual_seed\n",
    "\n",
    "        torch.manual_seed(manual_seed)\n",
    "        self.WQ = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "        self.WK = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "        self.WV = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "        self.d_k = self.WK.shape[-1]\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Computing context vectors utilizing the self-attention mechanism\n",
    "        :param X:\n",
    "        :return: Context vectors\n",
    "        \"\"\"\n",
    "        #Projecting input X onto the key, query, and value vectors\n",
    "        Q = X @ self.WQ\n",
    "        K = X @ self.WK\n",
    "        V = X @ self.WV\n",
    "\n",
    "        #d_k = self.WK.shape[-1]\n",
    "        attention_scores = Q @ K.transpose(0, 1)\n",
    "        attention_weights = torch.softmax(attention_scores / (self.d_k ** 0.5), dim = 1)\n",
    "        #Enriched input vector with contribution from other vectors\n",
    "        context_vectors = attention_weights @ V\n",
    "\n",
    "        return context_vectors\n"
   ],
   "id": "e530998e83e37def",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.744653Z",
     "start_time": "2025-11-13T19:30:12.738469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SelfAttentionV2(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out = 2, manual_seed = 123, qkv_bias = False):\n",
    "        super(SelfAttentionV2, self).__init__()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.manual_seed = manual_seed\n",
    "        self.qkv_bias = qkv_bias\n",
    "\n",
    "        torch.manual_seed(manual_seed)\n",
    "        self.WQ = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WK = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WV = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.d_k = d_out\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Computing context vectors utilizing the self-attention mechanism\n",
    "        :param X:\n",
    "        :return: Context vectors\n",
    "        \"\"\"\n",
    "        #Projecting input X onto the key, query, and value vectors\n",
    "        Q = self.WQ(X)\n",
    "        K = self.WK(X)\n",
    "        V = self.WV(X)\n",
    "\n",
    "        #d_k = self.WK.shape[-1]\n",
    "        attention_scores = Q @ K.transpose(0, 1)\n",
    "        attention_weights = torch.softmax(attention_scores / (self.d_k ** 0.5), dim = 1)\n",
    "        #Enriched input vector with contribution from other vectors\n",
    "        context_vectors = attention_weights @ V\n",
    "\n",
    "        return context_vectors\n"
   ],
   "id": "74c600f2d5ff6289",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.799551Z",
     "start_time": "2025-11-13T19:30:12.792291Z"
    }
   },
   "cell_type": "code",
   "source": "sattn = SelfAttentionV2(d_in, d_out)",
   "id": "d30e086ab58965b6",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.818800Z",
     "start_time": "2025-11-13T19:30:12.808879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Different result due to the different default lInear layer initialization\n",
    "sattn(X)"
   ],
   "id": "801ed9c3efc2ac58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5337, -0.1051],\n",
       "        [-0.5323, -0.1080],\n",
       "        [-0.5323, -0.1079],\n",
       "        [-0.5297, -0.1076],\n",
       "        [-0.5311, -0.1066],\n",
       "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:30:12.881918Z",
     "start_time": "2025-11-13T19:30:12.876818Z"
    }
   },
   "cell_type": "code",
   "source": "sattn.WQ.weight",
   "id": "b4908bf2206fd238",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2354,  0.0191, -0.2867],\n",
       "        [ 0.2177, -0.4919,  0.4232]], requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.5. Hiding future words with attention maps.",
   "id": "df9ea5d5f3459fcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.5.1 Applying casual attention mask.",
   "id": "11e3ecfdea60c8ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:34:12.939200Z",
     "start_time": "2025-11-13T19:34:12.922734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_length = 6\n",
    "mask = torch.tril(torch.ones(context_length, context_length))\n",
    "masked = attention_scores.masked_fill(mask.bool(), -torch.inf)"
   ],
   "id": "23a0096c6c953142",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:34:14.619576Z",
     "start_time": "2025-11-13T19:34:14.611897Z"
    }
   },
   "cell_type": "code",
   "source": "mask",
   "id": "7b9bd19cfe776446",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:23:09.536039Z",
     "start_time": "2025-11-15T17:23:09.524211Z"
    }
   },
   "cell_type": "code",
   "source": "masked",
   "id": "c6d9b07dcfb9c6b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -inf, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
       "        [  -inf,   -inf, 1.8111, 1.0795, 0.5577, 1.5440],\n",
       "        [  -inf,   -inf,   -inf, 1.0654, 0.5508, 1.5238],\n",
       "        [  -inf,   -inf,   -inf,   -inf, 0.3061, 0.8475],\n",
       "        [  -inf,   -inf,   -inf,   -inf,   -inf, 0.7307],\n",
       "        [  -inf,   -inf,   -inf,   -inf,   -inf,   -inf]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:22:41.000715Z",
     "start_time": "2025-11-15T17:22:40.979288Z"
    }
   },
   "cell_type": "code",
   "source": "torch.triu(torch.ones(context_length, context_length), diagonal = 1)",
   "id": "ef9127b7644cd5f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "9.5.2 Masking additional attention weights with dropout",
   "id": "6518fcc2ae2acf05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T16:36:49.000892Z",
     "start_time": "2025-11-15T16:36:48.990396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "layer = torch.nn.Dropout(0.5)"
   ],
   "id": "b264d67cbc42485a",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T16:36:49.520812Z",
     "start_time": "2025-11-15T16:36:49.493897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example = torch.ones(6,6)\n",
    "layer(example)"
   ],
   "id": "3657531fb24dc795",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 0., 2., 2., 0.],\n",
       "        [0., 0., 0., 2., 0., 2.],\n",
       "        [2., 2., 2., 2., 0., 2.],\n",
       "        [0., 2., 2., 0., 0., 2.],\n",
       "        [0., 2., 0., 2., 0., 2.],\n",
       "        [0., 2., 2., 2., 2., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.5.3 Creating compact casual attention self-attention class.",
   "id": "db466fdb73fe056b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T17:14:39.592925Z",
     "start_time": "2025-11-15T17:14:39.570027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = torch.stack((inputs, inputs), dim = 0)\n",
    "batch.size()"
   ],
   "id": "9bd96cc018962726",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T20:14:21.157345Z",
     "start_time": "2025-11-15T20:14:21.150655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Initial draft - Self Attention with Casual Mask\n",
    "class CasualAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, manual_seed = 123, dropout_rate = 0.1, qkv_bias = False):\n",
    "        super(CasualAttention, self).__init__()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.manual_seed = manual_seed\n",
    "        self.context_length = context_length\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.qkv_bias = qkv_bias\n",
    "        self.register_buffer('casual_mask', torch.triu(torch.ones(context_length, context_length), diagonal = 1))\n",
    "\n",
    "        torch.manual_seed(manual_seed)\n",
    "        self.WQ = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WK = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WV = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.d_k = d_out\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(self.dropout_rate)\n",
    "        #self.casual_mask = torch.tril(torch.ones(self., context_length))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Computing context vectors utilizing the self-attention mechanism\n",
    "        :param X: (batch_size, sequence_length, d_in)\n",
    "        :return: Context vectors\n",
    "        \"\"\"\n",
    "        #Projecting input X onto the key, query, and value vectors\n",
    "        Q = self.WQ(X)\n",
    "        K = self.WK(X)\n",
    "        V = self.WV(X)\n",
    "\n",
    "        #d_k = self.WK.shape[-1]\n",
    "        attention_scores = Q @ K.transpose(1, 2)\n",
    "        num_tokens = X.size(1)\n",
    "        attention_scores = attention_scores.masked_fill(self.casual_mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attention_weights = torch.softmax(attention_scores / (self.d_k ** 0.5), dim = -1)\n",
    "        print(attention_weights)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        #Enriched input vector with contribution from other vectors\n",
    "        context_vectors = attention_weights @ V\n",
    "\n",
    "        return context_vectors"
   ],
   "id": "8bbe51153836f47e",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T20:14:22.412279Z",
     "start_time": "2025-11-15T20:14:22.395626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "casualAttn = CasualAttention(d_in = batch.size(-1), d_out = 2, context_length = 1024, dropout_rate = 0.0, manual_seed = 123 ) #.to('cuda')\n",
    "#casualAttn(batch.to('cuda'))\n",
    "casualAttn(batch)"
   ],
   "id": "b6bfb2cb669ccf17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4519,  0.2216],\n",
       "         [-0.5874,  0.0058],\n",
       "         [-0.6300, -0.0632],\n",
       "         [-0.5675, -0.0843],\n",
       "         [-0.5526, -0.0981],\n",
       "         [-0.5299, -0.1081]],\n",
       "\n",
       "        [[-0.4519,  0.2216],\n",
       "         [-0.5874,  0.0058],\n",
       "         [-0.6300, -0.0632],\n",
       "         [-0.5675, -0.0843],\n",
       "         [-0.5526, -0.0981],\n",
       "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T19:18:14.939934Z",
     "start_time": "2025-11-15T19:18:14.929485Z"
    }
   },
   "cell_type": "markdown",
   "source": "3.6 Extending single-head attention with multi-head attention.",
   "id": "336ca1d9db257f22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.6.1 Stacking multiple single-head attention layers",
   "id": "ca547321b1275d17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T20:44:03.012851Z",
     "start_time": "2025-11-15T20:44:03.005575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttentionWrapper(torch.nn.Module):\n",
    "    def __init__(self, num_heads, d_in, d_out, context_length, manual_seed = 123, dropout_rate = 0.1, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
    "        self.heads = torch.nn.ModuleList([CasualAttention(d_in , d_out, context_length, dropout_rate = dropout_rate, manual_seed = manual_seed, qkv_bias = qkv_bias ) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, X):\n",
    "        return torch.cat([head(X) for head in self.heads], dim = -1)\n"
   ],
   "id": "5c7df89dc969b029",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T20:44:03.560256Z",
     "start_time": "2025-11-15T20:44:03.519007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mha = MultiHeadAttentionWrapper(num_heads = 2, d_in = d_in, d_out = d_out, context_length = context_length, manual_seed = 123, dropout_rate = 0.0)\n",
    "mha(batch)"
   ],
   "id": "ed5679cb5beb9f63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4519,  0.2216, -0.4519,  0.2216],\n",
       "         [-0.5874,  0.0058, -0.5874,  0.0058],\n",
       "         [-0.6300, -0.0632, -0.6300, -0.0632],\n",
       "         [-0.5675, -0.0843, -0.5675, -0.0843],\n",
       "         [-0.5526, -0.0981, -0.5526, -0.0981],\n",
       "         [-0.5299, -0.1081, -0.5299, -0.1081]],\n",
       "\n",
       "        [[-0.4519,  0.2216, -0.4519,  0.2216],\n",
       "         [-0.5874,  0.0058, -0.5874,  0.0058],\n",
       "         [-0.6300, -0.0632, -0.6300, -0.0632],\n",
       "         [-0.5675, -0.0843, -0.5675, -0.0843],\n",
       "         [-0.5526, -0.0981, -0.5526, -0.0981],\n",
       "         [-0.5299, -0.1081, -0.5299, -0.1081]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c5ed79df71a0c1f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "19a40ab7215ebe78"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
