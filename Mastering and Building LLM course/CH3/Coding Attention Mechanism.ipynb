{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "3.3.1  simple self-attention mechanism without weights",
   "id": "2324fe7f2ea6bbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:39.616065Z",
     "start_time": "2025-12-31T10:16:39.584309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import manual_seed\n",
    "from win32inetcon import WINHTTP_QUERY_MAX"
   ],
   "id": "8d19f7bab9eca2e0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:39.660557Z",
     "start_time": "2025-12-31T10:16:39.619186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ],
   "id": "202896967699c986",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:39.693461Z",
     "start_time": "2025-12-31T10:16:39.664447Z"
    }
   },
   "cell_type": "code",
   "source": "input_query = inputs[1]",
   "id": "98304f08111b3a1f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:39.817541Z",
     "start_time": "2025-12-31T10:16:39.696971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention_scores = torch.matmul(inputs, inputs.transpose(0, 1))\n",
    "attention_weights = torch.softmax(attention_scores, dim = 1)\n",
    "context_vectors = torch.matmul(attention_weights, inputs)"
   ],
   "id": "b4fb2bd553736cb4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:59.367126Z",
     "start_time": "2025-12-31T10:16:59.358400Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights",
   "id": "eaa2f94996402b9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
       "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
       "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
       "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
       "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
       "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:39.968110Z",
     "start_time": "2025-12-31T10:16:39.957391Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights.sum(dim=1)",
   "id": "ad7621cbae42287a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:49.489239Z",
     "start_time": "2025-12-31T10:16:49.478665Z"
    }
   },
   "cell_type": "code",
   "source": "context_vectors",
   "id": "608d7c73e4427a33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T13:02:28.120226Z",
     "start_time": "2025-10-26T13:02:28.109156Z"
    }
   },
   "cell_type": "markdown",
   "source": "3.4 Implementing Self-Attention Weights with trainable weights",
   "id": "207ed1ef34e352f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:49.976459Z",
     "start_time": "2025-12-31T10:16:49.970663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ],
   "id": "bcc6bf8f7c5b2814",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:50.040714Z",
     "start_time": "2025-12-31T10:16:49.978865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "WQ = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "WK = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "WV = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)"
   ],
   "id": "cfef2a2a72c55de4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:50.915494Z",
     "start_time": "2025-12-31T10:16:50.910119Z"
    }
   },
   "cell_type": "code",
   "source": "X = inputs",
   "id": "637489a30678851f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:51.078381Z",
     "start_time": "2025-12-31T10:16:51.063482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Q = X @ WQ\n",
    "K = X @ WK\n",
    "V = X @ WV"
   ],
   "id": "2cffc3830c8a63ca",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:51.758500Z",
     "start_time": "2025-12-31T10:16:51.751089Z"
    }
   },
   "cell_type": "code",
   "source": "Q.requires_grad",
   "id": "393760fcfd98cfbf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:51.790526Z",
     "start_time": "2025-12-31T10:16:51.760870Z"
    }
   },
   "cell_type": "code",
   "source": "K",
   "id": "14b2b70e5a8995be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3669, 0.7646],\n",
       "        [0.4433, 1.1419],\n",
       "        [0.4361, 1.1156],\n",
       "        [0.2408, 0.6706],\n",
       "        [0.1827, 0.3292],\n",
       "        [0.3275, 0.9642]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:52.206209Z",
     "start_time": "2025-12-31T10:16:52.200613Z"
    }
   },
   "cell_type": "code",
   "source": "attention_scores = Q @ K.transpose(0, 1)",
   "id": "1303b8a0c1032a3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:52.251302Z",
     "start_time": "2025-12-31T10:16:52.239953Z"
    }
   },
   "cell_type": "code",
   "source": "attention_scores",
   "id": "d1525553f624c866",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
       "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
       "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
       "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
       "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
       "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:52.974120Z",
     "start_time": "2025-12-31T10:16:52.958159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#transformation normalization\n",
    "d_k = WK.shape[-1]\n",
    "attention_weights = torch.softmax(attention_scores / (d_k ** 0.5), dim = 1)"
   ],
   "id": "dcc2ac9447e6f723",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:53.046285Z",
     "start_time": "2025-12-31T10:16:53.033664Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights",
   "id": "f49cccd1aad43619",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
       "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
       "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
       "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
       "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
       "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:53.790523Z",
     "start_time": "2025-12-31T10:16:53.772336Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights.sum(dim=1)",
   "id": "d488accfacb6c8b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:53.866617Z",
     "start_time": "2025-12-31T10:16:53.855898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_vectors = attention_weights @ V\n",
    "context_vectors"
   ],
   "id": "d7d06a1788e5b234",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2996, 0.8053],\n",
       "        [0.3061, 0.8210],\n",
       "        [0.3058, 0.8203],\n",
       "        [0.2948, 0.7939],\n",
       "        [0.2927, 0.7891],\n",
       "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T08:40:09.890089Z",
     "start_time": "2025-10-28T08:40:09.880436Z"
    }
   },
   "cell_type": "markdown",
   "source": "3.4.2 Implementing compact self-attention Pytorch class",
   "id": "552cbb143bfc8bff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:54.399549Z",
     "start_time": "2025-12-31T10:16:54.393041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = inputs\n",
    "d_in = X.size(-1)\n",
    "d_out = 2"
   ],
   "id": "e9553ac1c866f2e9",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:54.476642Z",
     "start_time": "2025-12-31T10:16:54.467757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SelfAttentionV1(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out = 2, manual_seed = 123):\n",
    "        super(SelfAttentionV1, self).__init__()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.manual_seed = manual_seed\n",
    "\n",
    "        torch.manual_seed(manual_seed)\n",
    "        self.WQ = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "        self.WK = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "        self.WV = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=True)\n",
    "        self.d_k = self.WK.shape[-1]\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Computing context vectors utilizing the self-attention mechanism\n",
    "        :param X:\n",
    "        :return: Context vectors\n",
    "        \"\"\"\n",
    "        #Projecting input X onto the key, query, and value vectors\n",
    "        Q = X @ self.WQ\n",
    "        K = X @ self.WK\n",
    "        V = X @ self.WV\n",
    "\n",
    "        #d_k = self.WK.shape[-1]\n",
    "        attention_scores = Q @ K.transpose(0, 1)\n",
    "        attention_weights = torch.softmax(attention_scores / (self.d_k ** 0.5), dim = 1)\n",
    "        #Enriched input vector with contribution from other vectors\n",
    "        context_vectors = attention_weights @ V\n",
    "\n",
    "        return context_vectors\n"
   ],
   "id": "e530998e83e37def",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:54.844465Z",
     "start_time": "2025-12-31T10:16:54.834860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SelfAttentionV2(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out = 2, manual_seed = 123, qkv_bias = False):\n",
    "        super(SelfAttentionV2, self).__init__()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.manual_seed = manual_seed\n",
    "        self.qkv_bias = qkv_bias\n",
    "\n",
    "        torch.manual_seed(manual_seed)\n",
    "        self.WQ = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WK = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WV = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.d_k = d_out\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Computing context vectors utilizing the self-attention mechanism\n",
    "        :param X:\n",
    "        :return: Context vectors\n",
    "        \"\"\"\n",
    "        #Projecting input X onto the key, query, and value vectors\n",
    "        Q = self.WQ(X)\n",
    "        K = self.WK(X)\n",
    "        V = self.WV(X)\n",
    "\n",
    "        #d_k = self.WK.shape[-1]\n",
    "        attention_scores = Q @ K.transpose(0, 1)\n",
    "        attention_weights = torch.softmax(attention_scores / (self.d_k ** 0.5), dim = 1)\n",
    "        #Enriched input vector with contribution from other vectors\n",
    "        context_vectors = attention_weights @ V\n",
    "\n",
    "        return context_vectors\n"
   ],
   "id": "74c600f2d5ff6289",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:54.894699Z",
     "start_time": "2025-12-31T10:16:54.847928Z"
    }
   },
   "cell_type": "code",
   "source": "sattn = SelfAttentionV2(d_in, d_out)",
   "id": "d30e086ab58965b6",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:55.066926Z",
     "start_time": "2025-12-31T10:16:55.042902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Different result due to the different default lInear layer initialization\n",
    "sattn(X)"
   ],
   "id": "801ed9c3efc2ac58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5337, -0.1051],\n",
       "        [-0.5323, -0.1080],\n",
       "        [-0.5323, -0.1079],\n",
       "        [-0.5297, -0.1076],\n",
       "        [-0.5311, -0.1066],\n",
       "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:55.142127Z",
     "start_time": "2025-12-31T10:16:55.132084Z"
    }
   },
   "cell_type": "code",
   "source": "sattn.WQ.weight",
   "id": "b4908bf2206fd238",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2354,  0.0191, -0.2867],\n",
       "        [ 0.2177, -0.4919,  0.4232]], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.5. Hiding future words with attention maps.",
   "id": "df9ea5d5f3459fcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.5.1 Applying casual attention mask.",
   "id": "11e3ecfdea60c8ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:55.459171Z",
     "start_time": "2025-12-31T10:16:55.434117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_length = 6\n",
    "mask = torch.tril(torch.ones(context_length, context_length))\n",
    "masked = attention_scores.masked_fill(mask.bool(), -torch.inf)"
   ],
   "id": "23a0096c6c953142",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:55.471073Z",
     "start_time": "2025-12-31T10:16:55.462435Z"
    }
   },
   "cell_type": "code",
   "source": "mask",
   "id": "7b9bd19cfe776446",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:55.944269Z",
     "start_time": "2025-12-31T10:16:55.934563Z"
    }
   },
   "cell_type": "code",
   "source": "masked",
   "id": "c6d9b07dcfb9c6b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -inf, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
       "        [  -inf,   -inf, 1.8111, 1.0795, 0.5577, 1.5440],\n",
       "        [  -inf,   -inf,   -inf, 1.0654, 0.5508, 1.5238],\n",
       "        [  -inf,   -inf,   -inf,   -inf, 0.3061, 0.8475],\n",
       "        [  -inf,   -inf,   -inf,   -inf,   -inf, 0.7307],\n",
       "        [  -inf,   -inf,   -inf,   -inf,   -inf,   -inf]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:56.078769Z",
     "start_time": "2025-12-31T10:16:56.065409Z"
    }
   },
   "cell_type": "code",
   "source": "torch.triu(torch.ones(context_length, context_length), diagonal = 1)",
   "id": "ef9127b7644cd5f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:30:37.025528Z",
     "start_time": "2025-12-31T10:30:37.013466Z"
    }
   },
   "cell_type": "code",
   "source": "torch.triu(torch.ones(context_length, context_length), diagonal = 1).bool()",
   "id": "c4a25bbc76a014c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:31:44.223929Z",
     "start_time": "2025-12-31T10:31:44.210062Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights.masked_fill(torch.triu(torch.ones(context_length, context_length), diagonal = 1).bool(), -torch.inf)",
   "id": "9b63c5f159af9ab7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1551,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.1500, 0.2264,   -inf,   -inf,   -inf,   -inf],\n",
       "        [0.1503, 0.2256, 0.2192,   -inf,   -inf,   -inf],\n",
       "        [0.1591, 0.1994, 0.1962, 0.1477,   -inf,   -inf],\n",
       "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265,   -inf],\n",
       "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "9.5.2 Masking additional attention weights with dropout",
   "id": "6518fcc2ae2acf05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:56.738300Z",
     "start_time": "2025-12-31T10:16:56.718456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "layer = torch.nn.Dropout(0.5)"
   ],
   "id": "b264d67cbc42485a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:56.863715Z",
     "start_time": "2025-12-31T10:16:56.836568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example = torch.ones(6,6)\n",
    "layer(example)"
   ],
   "id": "3657531fb24dc795",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 0., 2., 2., 0.],\n",
       "        [0., 0., 0., 2., 0., 2.],\n",
       "        [2., 2., 2., 2., 0., 2.],\n",
       "        [0., 2., 2., 0., 0., 2.],\n",
       "        [0., 2., 0., 2., 0., 2.],\n",
       "        [0., 2., 2., 2., 2., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.5.3 Creating compact casual attention self-attention class.",
   "id": "db466fdb73fe056b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:57.728737Z",
     "start_time": "2025-12-31T10:16:57.707851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = torch.stack((inputs, inputs), dim = 0)\n",
    "batch.size()"
   ],
   "id": "9bd96cc018962726",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:57.783488Z",
     "start_time": "2025-12-31T10:16:57.772436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Initial draft - Self Attention with Casual Mask\n",
    "class CasualAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, manual_seed = 123, dropout_rate = 0.1, qkv_bias = False):\n",
    "        super(CasualAttention, self).__init__()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.manual_seed = manual_seed\n",
    "        self.context_length = context_length\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.qkv_bias = qkv_bias\n",
    "        self.register_buffer('casual_mask', torch.triu(torch.ones(context_length, context_length), diagonal = 1))\n",
    "\n",
    "        torch.manual_seed(manual_seed)\n",
    "        self.WQ = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WK = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WV = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.d_k = d_out\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(self.dropout_rate)\n",
    "        #self.casual_mask = torch.tril(torch.ones(self., context_length))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Computing context vectors utilizing the self-attention mechanism\n",
    "        :param X: (batch_size, sequence_length, d_in)\n",
    "        :return: Context vectors\n",
    "        \"\"\"\n",
    "        #Projecting input X onto the key, query, and value vectors\n",
    "        Q = self.WQ(X)\n",
    "        K = self.WK(X)\n",
    "        V = self.WV(X)\n",
    "\n",
    "        #d_k = self.WK.shape[-1]\n",
    "        attention_scores = Q @ K.transpose(1, 2)\n",
    "        num_tokens = X.size(1)\n",
    "        attention_scores = attention_scores.masked_fill(self.casual_mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attention_weights = torch.softmax(attention_scores / (self.d_k ** 0.5), dim = -1)\n",
    "        print(attention_weights)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        #Enriched input vector with contribution from other vectors\n",
    "        context_vectors = attention_weights @ V\n",
    "\n",
    "        return context_vectors"
   ],
   "id": "8bbe51153836f47e",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:58.235225Z",
     "start_time": "2025-12-31T10:16:58.174900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "casualAttn = CasualAttention(d_in = batch.size(-1), d_out = 2, context_length = 1024, dropout_rate = 0.0, manual_seed = 123 ) #.to('cuda')\n",
    "#casualAttn(batch.to('cuda'))\n",
    "casualAttn(batch)"
   ],
   "id": "b6bfb2cb669ccf17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4519,  0.2216],\n",
       "         [-0.5874,  0.0058],\n",
       "         [-0.6300, -0.0632],\n",
       "         [-0.5675, -0.0843],\n",
       "         [-0.5526, -0.0981],\n",
       "         [-0.5299, -0.1081]],\n",
       "\n",
       "        [[-0.4519,  0.2216],\n",
       "         [-0.5874,  0.0058],\n",
       "         [-0.6300, -0.0632],\n",
       "         [-0.5675, -0.0843],\n",
       "         [-0.5526, -0.0981],\n",
       "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T19:18:14.939934Z",
     "start_time": "2025-11-15T19:18:14.929485Z"
    }
   },
   "cell_type": "markdown",
   "source": "3.6 Extending single-head attention with multi-head attention.",
   "id": "336ca1d9db257f22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.6.1 Stacking multiple single-head attention layers",
   "id": "ca547321b1275d17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:58.247551Z",
     "start_time": "2025-12-31T10:16:58.238637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttentionWrapper(torch.nn.Module):\n",
    "    def __init__(self, num_heads, d_in, d_out, context_length, manual_seed = 123, dropout_rate = 0.1, qkv_bias = False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
    "        self.heads = torch.nn.ModuleList([CasualAttention(d_in , d_out, context_length, dropout_rate = dropout_rate, manual_seed = manual_seed, qkv_bias = qkv_bias ) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, X):\n",
    "        return torch.cat([head(X) for head in self.heads], dim = -1)\n"
   ],
   "id": "5c7df89dc969b029",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:58.654171Z",
     "start_time": "2025-12-31T10:16:58.607379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mha = MultiHeadAttentionWrapper(num_heads = 2, d_in = d_in, d_out = d_out, context_length = context_length, manual_seed = 123, dropout_rate = 0.0)\n",
    "mha(batch)"
   ],
   "id": "ed5679cb5beb9f63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "         [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "         [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4519,  0.2216, -0.4519,  0.2216],\n",
       "         [-0.5874,  0.0058, -0.5874,  0.0058],\n",
       "         [-0.6300, -0.0632, -0.6300, -0.0632],\n",
       "         [-0.5675, -0.0843, -0.5675, -0.0843],\n",
       "         [-0.5526, -0.0981, -0.5526, -0.0981],\n",
       "         [-0.5299, -0.1081, -0.5299, -0.1081]],\n",
       "\n",
       "        [[-0.4519,  0.2216, -0.4519,  0.2216],\n",
       "         [-0.5874,  0.0058, -0.5874,  0.0058],\n",
       "         [-0.6300, -0.0632, -0.6300, -0.0632],\n",
       "         [-0.5675, -0.0843, -0.5675, -0.0843],\n",
       "         [-0.5526, -0.0981, -0.5526, -0.0981],\n",
       "         [-0.5299, -0.1081, -0.5299, -0.1081]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.6.2 Efficient Multi-Head Attention",
   "id": "abfa23a97f1a103e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:58.664430Z",
     "start_time": "2025-12-31T10:16:58.656178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],    #1\n",
    "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
    "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
    "\n",
    "                   [[0.0772, 0.3565, 0.1479, 0.5331],\n",
    "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
    "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])"
   ],
   "id": "c5ed79df71a0c1f1",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:58.882961Z",
     "start_time": "2025-12-31T10:16:58.870125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, num_heads, d_in, d_out, context_length, manual_seed = 123, dropout_rate = 0.1, qkv_bias = False):\n",
    "        assert d_out % num_heads == 0, \"output dimension must be divisible by unmber of heads\"\n",
    "\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        self.num_heads = num_heads\n",
    "        self.h_dim = d_out // num_heads\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.manual_seed = manual_seed\n",
    "        self.context_length = context_length\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.qkv_bias = qkv_bias\n",
    "        self.register_buffer('casual_mask', torch.triu(torch.ones(context_length, context_length), diagonal = 1))\n",
    "\n",
    "        torch.manual_seed(manual_seed)\n",
    "        self.WQ = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WK = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.WV = torch.nn.Linear(d_in, d_out, bias = self.qkv_bias)\n",
    "        self.d_k = d_out\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(self.dropout_rate)\n",
    "        #self.casual_mask = torch.tril(torch.ones(self., context_length))\n",
    "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Computing context vectors utilizing the self-attention mechanism\n",
    "        :param X: (batch_size, sequence_length, d_in)\n",
    "        :return: Context vectors\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, num_tokens, d_in = X.size()\n",
    "\n",
    "        #Projecting input X onto the key, query, and value vectors\n",
    "        Q = self.WQ(X)\n",
    "        K = self.WK(X)\n",
    "        V = self.WV(X)\n",
    "\n",
    "        Q = Q.view(batch_size, num_tokens, self.num_heads, self.h_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, num_tokens, self.num_heads, self.h_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, num_tokens, self.num_heads, self.h_dim) .transpose(1, 2)\n",
    "\n",
    "        #d_k = self.WK.shape[-1]\n",
    "        attention_scores = Q @ K.transpose(2, 3)\n",
    "        attention_scores = attention_scores.masked_fill(self.casual_mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attention_weights = torch.softmax(attention_scores / (K.size(-1) ** 0.5), dim = -1)\n",
    "        #print(attention_weights)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        #Enriched input vector with contribution from other vectors\n",
    "        context_vectors = (attention_weights @ V).transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
    "        context_vectors = self.out_proj(context_vectors)\n",
    "\n",
    "        return context_vectors"
   ],
   "id": "19a40ab7215ebe78",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:58.898630Z",
     "start_time": "2025-12-31T10:16:58.885802Z"
    }
   },
   "cell_type": "code",
   "source": "batch.size()",
   "id": "e1ef7b68020f8053",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:59.173650Z",
     "start_time": "2025-12-31T10:16:59.143065Z"
    }
   },
   "cell_type": "code",
   "source": "mha = MultiHeadAttention(num_heads = 2, d_in = 3, d_out =4, context_length = context_length, manual_seed = 123, dropout_rate = 0.0)",
   "id": "85cc8a570b7d3ca0",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:59.197330Z",
     "start_time": "2025-12-31T10:16:59.176696Z"
    }
   },
   "cell_type": "code",
   "source": "mha(batch)",
   "id": "4f7d62b21cf80262",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1184,  0.3120, -0.0847, -0.5774],\n",
       "         [ 0.0178,  0.3221, -0.0763, -0.4225],\n",
       "         [-0.0147,  0.3259, -0.0734, -0.3721],\n",
       "         [-0.0116,  0.3138, -0.0708, -0.3624],\n",
       "         [-0.0117,  0.2973, -0.0698, -0.3543],\n",
       "         [-0.0132,  0.2990, -0.0689, -0.3490]],\n",
       "\n",
       "        [[ 0.1184,  0.3120, -0.0847, -0.5774],\n",
       "         [ 0.0178,  0.3221, -0.0763, -0.4225],\n",
       "         [-0.0147,  0.3259, -0.0734, -0.3721],\n",
       "         [-0.0116,  0.3138, -0.0708, -0.3624],\n",
       "         [-0.0117,  0.2973, -0.0698, -0.3543],\n",
       "         [-0.0132,  0.2990, -0.0689, -0.3490]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-31T10:16:59.347383Z",
     "start_time": "2025-12-31T10:16:59.343735Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "820be754888d5de3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
